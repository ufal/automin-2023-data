So now, the voice level of the amplification should be reasonable. It's only some mountains above that should be ideally, the presentation from [PERSON9]'s notebook. So the way we are presenting the subtitles, for now, is only directly when the worker. Screensharing, share my screen,<czech speaking="">

So you should be seeing. (PERSON6) Ehm, I think <unintelligible> maybe down, <unintelligible>

(PERSON12) Yeah, please test- test German worker and [PERSON11] can at the same time start third window, right? One of the command is running only the ASR worker and the other command the lower window is running both, the ASR worker and the machine translation into Czech. And I would like a third one, which would be also doing the machine translation into German. And this is the set up where all the workers are totally like independent. And the same ASR processing is done two times now, and it will be done three times with the German one. (PERSON6) <unintelligible>

(PERSON7) Sorry, we don't have machine <unintelligible> system, but we could try test the ASR if you want. So for the for the workshop actually, it's it's seems that we are short of German interpreters. So that is at least one benefit of our technology that it should, if it runs it runs. But anyway, we should be ready for for that, because the German from the ASR will be much better and German speakers will be much happier to see uh, the the human interpretation, but we should be testing everything. And we also noticed that I don't know how to share it,how to do it. So look at look at my screen, look at the web cam that I'm presenting now. So I 'm sharing my whole screen but the full motion icon has has hidden away has hidden away. (PERSON7) That was clear <unintelligible> suited for connection so, the HD one. So the first issue that we spotted was that we need life monitoring of everything. If anything is bad we need to trace one step back and see if it was good and this step back or or not. (PERSON3) Haven't you tested the- multipol input stream request? It's not correct and it bounce also the usages to the key worker. (PERSON3) No, no, it should be the same issue, but I also, I'm a little bit confused the on this topic, than probably I haven't explain it very well. We do want to display the same thing twice, if it was set twice. Your empty worker could save the uh, the graphics card, or whatever the CP use, time and could cash it. (PERSON12) Yeah, I think the the empty worker should be totally like ignoring any context. (PERSON12) I think it's what we want, because like it's very same string then the empty worker should not have been called. (PERSON3) I I run a test with the English ASR, maybe it was me. And and [PERSON11]'s notebook not recording anything yet, but the beringer we have, the sound in the sound card, but we do not have the sound in the system, and it's stopped by itself, or have you been changing any of the sound settings? In the mean-We could we could have some discussion so that I would be stoking only once a while on something useful. (PERSON3) The English machine translation, and then publish an English subtitle. So please use the repository of [PROJECT1] to upload at least that part that runs the. At least the webpage that shows the video and this is the thing that we need to link with the screencast that we are going to to send. And actually we're still working on the integration for example, we have some problems with characters and coding, right now. But the English subtitle which of course the English language doesn't have. Strange characters is also- perfectly representing letting one. For the Czech,we definitely need more we need also letting 2 or UTF8. So sending the audio and your presentation platform showing the subtitles corresponding to that. There are for example, for sure, the German,Italian, ok, and the English one. (PERSON12) So can we also present to-unable-I'll show you the, on the-

(PERSON11) I'm sharing the screen so-

(PERSON12) You can look at [PERSON11]'s screen in in Pexip. And we have still some problem with of course browsers and Windows. Ok, so what is your main conlusion recall before you leaving from this test. (PERSON7) <unintelligible> in the document is that I said I'm not quite understand the logic in the ASR, because it's giving us sentences in <unintelligible> fragments <unintelligible>

So if it could talk to <unintelligible> maybe they can change the way that this is present I think it will be helpful for us. (PERSON3) Yes, from yesterday I start working on the complete pipe. Ok, so let's plan to have the same type of test call on Fri- on Friday anyway. It could happen at the [ORGANIZATION4] side with the machine translation systems. I would just like to ask if you could get in touch directly with [PERSON5] and make sure that they help you with the with segmentation input. (PERSON12) And [PERSON3], you're still available for some time? We don't have access to the um, maybe you can, yes, if you know, you can tell us how to use the streaming from VLC that work for you. (PERSON12) Yeah, ok, but is there-

Can you at least well, I don't recognize if you are else. And what actually happened with the ban, it's still confusing to me. Of course you will not have future video chance, you have just the right now chunk. I'm not guru of streaming video streaming button, as far as I know, it works exactly this way. I brought the Google doc, the bunny M3U8 URL, you can use to test it. (PERSON3) <unintelligible> of course you have to be registered, let's say to the system as administrator. In this case you see the ehm the main page, possible by each one has <unintelligible>  the browser. So in the meantime, [PERSON4] said that he was, he made himself available on Slack. So, and Google,Firefox anywhere and Google Chrome on Windows. I think we should we should try to wrap up, so I would like to ask everybody who is still on the call, to go through the the current state of the Google document, and add whatever we have not recorded in the-

And make make the transcript or summary of the messages clear. Because I'm afraid that we have seen many things, but we have not taken appropriate record of all of them. Because, well, the application it's dummy, it's simply displays what he recieves. (PERSON3) Unfortunately, I'm not able-

Oh maybe it work,yes. (PERSON3) Ok, if at the moment the definition of sources is static, it's not dynamic, it's pretty difficult to define exactly the logic of joining services and living services we're still reasoning about it. But actually this will effect the next part of the configuration which is the one related to the language configuration. (PERSON12) Yeah, so the point is that if there is a worker connected to the mediator, there is no way for us to change it's fingerprints. (PERSON11) But, but at least I created bridge worker, I updated the backend SMT worker so we can specify the fingerprints <unintelligible> arguments and disconcert us bridge between workers. (PERSON12) Yeah, so [PERSON3] I'll paste it to your, oh this is too bad. And as- so simply by adding these languages to this list, the worker, it's registering these new workers, right? And the the EB client connects to the mediator and the mediator find the path and the path will include the worker which digest Italian text and produces Italian pub. (PERSON12) Yeah, so please do it with the set of languages that we need for the-

So it's now fingerprint. (PERSON9) No I don't have it here.<czech language="">

(PERSON12) Does it work on Chromium? (PERSON3) You guys of course the browser, maybe it's related to Windows firewall but you are running Linux, we have to check it, ok. Actually it work also on my mobile device, so maybe you can try with your Android device to connect to the presentation platform by using browser. (PERSON12) I'm not sure if I'm, I'm sharing the screen, I'll share my camera instead. They will sit in front of a notebook, each one of them and they will see the subtitles and the slides. (PERSON12) Yeah, so this is this is the full screen mode of the web browser, what you're seeing in the webcam from my Pexip, right? (PERSON9) Also small <unintelligible> given the small set of languages now-

(PERSON12) So this is my, this is my screen and also I think it's like not really-

So the Bugs  works yes, it's good. For the desktops it would be better to to have the subt- the video larger. It should also happily use the whole the full width of of that. So, because you mention the number of where is that should be displayed. And it's difficult to explain to someone else also how how it work. But I can prepare some kind of snippet and I can share them for sure. And this is something that would help us to to use the video mixer if we use some transparent transparent ehm terminal on green screen. Because it we we could make it clie- console operation worker. (PERSON3) Yes, please consider that at the moment, the publication worker it's running on my local PC. (PERSON3) In general I suggest you to forget about the presentation platform till Monday.<laughing>

So we can test and improve the functionality. So the multiple language fingerprint path selection and hopefully, of course the multiple publishing system on the presentation platform. I'm now editing the top, you're seeing it in in my screeshare I guess. I'm sorry it didn't work today, but actually <unintelligible>

(PERSON12) That's it's no no, you're pretty fire, this is perfect.